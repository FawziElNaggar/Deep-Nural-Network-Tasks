{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment_1_Day1_ANN.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VrWl1YxPu9XX"
      },
      "source": [
        "## Name : Fawzi abdelnaby elsayed\n",
        "## Group : One(Mansoura)\n",
        "## Assignment_1_Day_1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "40wlLpn0vL33"
      },
      "source": [
        "## One perceptron with one input layer and one output neuron"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-q954RVQu5VZ",
        "outputId": "76b82354-3b26-4cf2-bbea-ca8172138b60"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "class NeuralNetwork():\n",
        "    \n",
        "    def __init__(self):\n",
        "        # seeding for random number generation\n",
        "        np.random.seed(1)\n",
        "        \n",
        "        #converting weights to a 3 by 1 matrix with values from -1 to 1 and mean of 0\n",
        "        self.synaptic_weights = 2 * np.random.random((3, 1)) - 1\n",
        "\n",
        "    def sigmoid(self, x):\n",
        "        #applying the sigmoid function\n",
        "        return 1 / (1 + np.exp(-x))\n",
        "\n",
        "    def sigmoid_derivative(self, x):\n",
        "        #computing derivative to the Sigmoid function\n",
        "        return x * (1 - x)\n",
        "\n",
        "    def train(self, training_inputs, training_outputs, training_iterations):\n",
        "        \n",
        "        #training the model to make accurate predictions while adjusting weights continually\n",
        "        for iteration in range(training_iterations):\n",
        "            #siphon the training data via  the neuron\n",
        "            output = self.think(training_inputs)\n",
        "\n",
        "            #computing error rate for back-propagation\n",
        "            error = training_outputs - output\n",
        "            \n",
        "            #performing weight adjustments\n",
        "            adjustments = np.dot(training_inputs.T, error * self.sigmoid_derivative(output))\n",
        "\n",
        "            self.synaptic_weights += adjustments\n",
        "\n",
        "    def think(self, inputs):\n",
        "        #passing the inputs via the neuron to get output   \n",
        "        #converting values to floats\n",
        "        \n",
        "        inputs = inputs.astype(float)\n",
        "        output = self.sigmoid(np.dot(inputs, self.synaptic_weights))\n",
        "        return output\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    #initializing the neuron class\n",
        "    neural_network = NeuralNetwork()\n",
        "\n",
        "    print(\"Beginning Randomly Generated Weights: \")\n",
        "    print(neural_network.synaptic_weights)\n",
        "\n",
        "    #training data consisting of 4 examples--3 input values and 1 output\n",
        "    training_inputs = np.array([[0,0,1],\n",
        "                                [1,1,1],\n",
        "                                [1,0,1],\n",
        "                                [0,1,1]])\n",
        "\n",
        "    training_outputs = np.array([[0,1,1,0]]).T\n",
        "\n",
        "    #training taking place\n",
        "    neural_network.train(training_inputs, training_outputs,1000)\n",
        "\n",
        "    print(\"Ending Weights After Training: \")\n",
        "    print(neural_network.synaptic_weights)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Beginning Randomly Generated Weights: \n",
            "[[-0.16595599]\n",
            " [ 0.44064899]\n",
            " [-0.99977125]]\n",
            "Ending Weights After Training: \n",
            "[[ 7.26283009]\n",
            " [-0.21614618]\n",
            " [-3.41703015]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OtM6JKiNvF_G"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}